{"ast":null,"code":"import _regeneratorRuntime from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _get from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _slicedToArray from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _createForOfIteratorHelper from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper\";\nimport _classCallCheck from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _inherits from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _createSuper from \"/Users/stefan_rmmr/software_dev/streamlit_audio_recorder/st_audiorec/frontend/node_modules/@babel/runtime/helpers/esm/createSuper\";\n\nfunction _asyncIterator(iterable) { var method, async, sync, retry = 2; for (\"undefined\" != typeof Symbol && (async = Symbol.asyncIterator, sync = Symbol.iterator); retry--;) { if (async && null != (method = iterable[async])) return method.call(iterable); if (sync && null != (method = iterable[sync])) return new AsyncFromSyncIterator(method.call(iterable)); async = \"@@asyncIterator\", sync = \"@@iterator\"; } throw new TypeError(\"Object is not async iterable\"); }\n\nfunction AsyncFromSyncIterator(s) { function AsyncFromSyncIteratorContinuation(r) { if (Object(r) !== r) return Promise.reject(new TypeError(r + \" is not an object.\")); var done = r.done; return Promise.resolve(r.value).then(function (value) { return { value: value, done: done }; }); } return AsyncFromSyncIterator = function AsyncFromSyncIterator(s) { this.s = s, this.n = s.next; }, AsyncFromSyncIterator.prototype = { s: null, n: null, next: function next() { return AsyncFromSyncIteratorContinuation(this.n.apply(this.s, arguments)); }, return: function _return(value) { var ret = this.s.return; return void 0 === ret ? Promise.resolve({ value: value, done: !0 }) : AsyncFromSyncIteratorContinuation(ret.apply(this.s, arguments)); }, throw: function _throw(value) { var thr = this.s.return; return void 0 === thr ? Promise.reject(value) : AsyncFromSyncIteratorContinuation(thr.apply(this.s, arguments)); } }, new AsyncFromSyncIterator(s); }\n\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { ReadableInterop } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\nexport var RecordBatchWriter = /*#__PURE__*/function (_ReadableInterop, _Symbol$asyncIterator) {\n  _inherits(RecordBatchWriter, _ReadableInterop);\n\n  var _super = _createSuper(RecordBatchWriter);\n\n  function RecordBatchWriter(options) {\n    var _this;\n\n    _classCallCheck(this, RecordBatchWriter);\n\n    _this = _super.call(this);\n    _this._position = 0;\n    _this._started = false; // @ts-ignore\n\n    _this._sink = new AsyncByteQueue();\n    _this._schema = null;\n    _this._dictionaryBlocks = [];\n    _this._recordBatchBlocks = [];\n    _this._dictionaryDeltaOffsets = new Map();\n    isObject(options) || (options = {\n      autoDestroy: true,\n      writeLegacyIpcFormat: false\n    });\n    _this._autoDestroy = typeof options.autoDestroy === 'boolean' ? options.autoDestroy : true;\n    _this._writeLegacyIpcFormat = typeof options.writeLegacyIpcFormat === 'boolean' ? options.writeLegacyIpcFormat : false;\n    return _this;\n  }\n  /** @nocollapse */\n  // @ts-ignore\n\n\n  _createClass(RecordBatchWriter, [{\n    key: \"toString\",\n    value: function toString() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toString(sync);\n    }\n  }, {\n    key: \"toUint8Array\",\n    value: function toUint8Array() {\n      var sync = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : false;\n      return this._sink.toUint8Array(sync);\n    }\n  }, {\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      var _this2 = this;\n\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return _this2.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(this, input);\n      }\n\n      return _writeAll(this, input);\n    }\n  }, {\n    key: \"closed\",\n    get: function get() {\n      return this._sink.closed;\n    }\n  }, {\n    key: _Symbol$asyncIterator,\n    value: function value() {\n      return this._sink[Symbol.asyncIterator]();\n    }\n  }, {\n    key: \"toDOMStream\",\n    value: function toDOMStream(options) {\n      return this._sink.toDOMStream(options);\n    }\n  }, {\n    key: \"toNodeStream\",\n    value: function toNodeStream(options) {\n      return this._sink.toNodeStream(options);\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      return this.reset()._sink.close();\n    }\n  }, {\n    key: \"abort\",\n    value: function abort(reason) {\n      return this.reset()._sink.abort(reason);\n    }\n  }, {\n    key: \"finish\",\n    value: function finish() {\n      this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n      return this;\n    }\n  }, {\n    key: \"reset\",\n    value: function reset() {\n      var sink = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : this._sink;\n      var schema = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n      if (sink === this._sink || sink instanceof AsyncByteQueue) {\n        this._sink = sink;\n      } else {\n        this._sink = new AsyncByteQueue();\n\n        if (sink && isWritableDOMStream(sink)) {\n          this.toDOMStream({\n            type: 'bytes'\n          }).pipeTo(sink);\n        } else if (sink && isWritableNodeStream(sink)) {\n          this.toNodeStream({\n            objectMode: false\n          }).pipe(sink);\n        }\n      }\n\n      if (this._started && this._schema) {\n        this._writeFooter(this._schema);\n      }\n\n      this._started = false;\n      this._dictionaryBlocks = [];\n      this._recordBatchBlocks = [];\n      this._dictionaryDeltaOffsets = new Map();\n\n      if (!schema || !schema.compareTo(this._schema)) {\n        if (schema === null) {\n          this._position = 0;\n          this._schema = null;\n        } else {\n          this._started = true;\n          this._schema = schema;\n\n          this._writeSchema(schema);\n        }\n      }\n\n      return this;\n    }\n  }, {\n    key: \"write\",\n    value: function write(payload) {\n      var schema = null;\n\n      if (!this._sink) {\n        throw new Error(\"RecordBatchWriter is closed\");\n      } else if (payload === null || payload === undefined) {\n        return this.finish() && undefined;\n      } else if (payload instanceof Table && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n        return this.finish() && undefined;\n      }\n\n      if (schema && !schema.compareTo(this._schema)) {\n        if (this._started && this._autoDestroy) {\n          return this.close();\n        }\n\n        this.reset(this._sink, schema);\n      }\n\n      if (payload instanceof RecordBatch) {\n        if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n          this._writeRecordBatch(payload);\n        }\n      } else if (payload instanceof Table) {\n        this.writeAll(payload.chunks);\n      } else if (isIterable(payload)) {\n        this.writeAll(payload);\n      }\n    }\n  }, {\n    key: \"_writeMessage\",\n    value: function _writeMessage(message) {\n      var alignment = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 8;\n      var a = alignment - 1;\n      var buffer = Message.encode(message);\n      var flatbufferSize = buffer.byteLength;\n      var prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n      var alignedSize = flatbufferSize + prefixSize + a & ~a;\n      var nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n      if (message.headerType === MessageHeader.RecordBatch) {\n        this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      } else if (message.headerType === MessageHeader.DictionaryBatch) {\n        this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n      } // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n\n\n      if (!this._writeLegacyIpcFormat) {\n        this._write(Int32Array.of(-1));\n      } // Write the flatbuffer size prefix including padding\n\n\n      this._write(Int32Array.of(alignedSize - prefixSize)); // Write the flatbuffer\n\n\n      if (flatbufferSize > 0) {\n        this._write(buffer);\n      } // Write any padding\n\n\n      return this._writePadding(nPaddingBytes);\n    }\n  }, {\n    key: \"_write\",\n    value: function _write(chunk) {\n      if (this._started) {\n        var buffer = toUint8Array(chunk);\n\n        if (buffer && buffer.byteLength > 0) {\n          this._sink.write(buffer);\n\n          this._position += buffer.byteLength;\n        }\n      }\n\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._writeMessage(Message.from(schema));\n    } // @ts-ignore\n\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      // eos bytes\n      return this._writeLegacyIpcFormat ? this._write(Int32Array.of(0)) : this._write(Int32Array.of(-1, 0));\n    }\n  }, {\n    key: \"_writeMagic\",\n    value: function _writeMagic() {\n      return this._write(MAGIC);\n    }\n  }, {\n    key: \"_writePadding\",\n    value: function _writePadding(nBytes) {\n      return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      var _VectorAssembler$asse = VectorAssembler.assemble(batch),\n          byteLength = _VectorAssembler$asse.byteLength,\n          nodes = _VectorAssembler$asse.nodes,\n          bufferRegions = _VectorAssembler$asse.bufferRegions,\n          buffers = _VectorAssembler$asse.buffers;\n\n      var recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n      var message = Message.from(recordBatch, byteLength);\n      return this._writeDictionaries(batch)._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n\n      var _VectorAssembler$asse2 = VectorAssembler.assemble(dictionary),\n          byteLength = _VectorAssembler$asse2.byteLength,\n          nodes = _VectorAssembler$asse2.nodes,\n          bufferRegions = _VectorAssembler$asse2.bufferRegions,\n          buffers = _VectorAssembler$asse2.buffers;\n\n      var recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n      var dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n      var message = Message.from(dictionaryBatch, byteLength);\n      return this._writeMessage(message)._writeBodyBuffers(buffers);\n    }\n  }, {\n    key: \"_writeBodyBuffers\",\n    value: function _writeBodyBuffers(buffers) {\n      var buffer;\n      var size, padding;\n\n      for (var i = -1, n = buffers.length; ++i < n;) {\n        if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n          this._write(buffer);\n\n          if ((padding = (size + 7 & ~7) - size) > 0) {\n            this._writePadding(padding);\n          }\n        }\n      }\n\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      var _iterator2 = _createForOfIteratorHelper(batch.dictionaries),\n          _step2;\n\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var _step2$value = _slicedToArray(_step2.value, 2),\n              id = _step2$value[0],\n              dictionary = _step2$value[1];\n\n          var offset = this._dictionaryDeltaOffsets.get(id) || 0;\n\n          if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n            var chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n\n            var _iterator3 = _createForOfIteratorHelper(chunks),\n                _step3;\n\n            try {\n              for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                var chunk = _step3.value;\n\n                this._writeDictionaryBatch(chunk, id, offset > 0);\n\n                offset += chunk.length;\n              }\n            } catch (err) {\n              _iterator3.e(err);\n            } finally {\n              _iterator3.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n\n      return this;\n    }\n  }], [{\n    key: \"throughNode\",\n    value: function throughNode(options) {\n      throw new Error(\"\\\"throughNode\\\" not available in this environment\");\n    }\n    /** @nocollapse */\n\n  }, {\n    key: \"throughDOM\",\n    value: function throughDOM( // @ts-ignore\n    writableStrategy, // @ts-ignore\n    readableStrategy) {\n      throw new Error(\"\\\"throughDOM\\\" not available in this environment\");\n    }\n  }]);\n\n  return RecordBatchWriter;\n}(ReadableInterop, Symbol.asyncIterator);\n/** @ignore */\n\nexport var RecordBatchStreamWriter = /*#__PURE__*/function (_RecordBatchWriter) {\n  _inherits(RecordBatchStreamWriter, _RecordBatchWriter);\n\n  var _super2 = _createSuper(RecordBatchStreamWriter);\n\n  function RecordBatchStreamWriter() {\n    _classCallCheck(this, RecordBatchStreamWriter);\n\n    return _super2.apply(this, arguments);\n  }\n\n  _createClass(RecordBatchStreamWriter, null, [{\n    key: \"writeAll\",\n    value:\n    /** @nocollapse */\n    function writeAll(input, options) {\n      var writer = new RecordBatchStreamWriter(options);\n\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n\n      return _writeAll(writer, input);\n    }\n  }]);\n\n  return RecordBatchStreamWriter;\n}(RecordBatchWriter);\n/** @ignore */\n\nexport var RecordBatchFileWriter = /*#__PURE__*/function (_RecordBatchWriter2) {\n  _inherits(RecordBatchFileWriter, _RecordBatchWriter2);\n\n  var _super3 = _createSuper(RecordBatchFileWriter);\n\n  function RecordBatchFileWriter() {\n    var _this3;\n\n    _classCallCheck(this, RecordBatchFileWriter);\n\n    _this3 = _super3.call(this);\n    _this3._autoDestroy = true;\n    return _this3;\n  }\n  /** @nocollapse */\n\n\n  _createClass(RecordBatchFileWriter, [{\n    key: \"_writeSchema\",\n    value: // @ts-ignore\n    function _writeSchema(schema) {\n      return this._writeMagic()._writePadding(2);\n    }\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      var buffer = Footer.encode(new Footer(schema, MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n      return _get(_getPrototypeOf(RecordBatchFileWriter.prototype), \"_writeFooter\", this).call(this, schema) // EOS bytes for sequential readers\n      ._write(buffer) // Write the flatbuffer\n      ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n      ._writeMagic(); // then the magic suffix\n    }\n  }], [{\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      var writer = new RecordBatchFileWriter();\n\n      if (isPromise(input)) {\n        return input.then(function (x) {\n          return writer.writeAll(x);\n        });\n      } else if (isAsyncIterable(input)) {\n        return writeAllAsync(writer, input);\n      }\n\n      return _writeAll(writer, input);\n    }\n  }]);\n\n  return RecordBatchFileWriter;\n}(RecordBatchWriter);\n/** @ignore */\n\nexport var RecordBatchJSONWriter = /*#__PURE__*/function (_RecordBatchWriter3) {\n  _inherits(RecordBatchJSONWriter, _RecordBatchWriter3);\n\n  var _super4 = _createSuper(RecordBatchJSONWriter);\n\n  function RecordBatchJSONWriter() {\n    var _this4;\n\n    _classCallCheck(this, RecordBatchJSONWriter);\n\n    _this4 = _super4.call(this);\n    _this4._autoDestroy = true;\n    _this4._recordBatches = [];\n    _this4._dictionaries = [];\n    return _this4;\n  }\n  /** @nocollapse */\n\n\n  _createClass(RecordBatchJSONWriter, [{\n    key: \"_writeMessage\",\n    value: function _writeMessage() {\n      return this;\n    } // @ts-ignore\n\n  }, {\n    key: \"_writeFooter\",\n    value: function _writeFooter(schema) {\n      return this;\n    }\n  }, {\n    key: \"_writeSchema\",\n    value: function _writeSchema(schema) {\n      return this._write(\"{\\n  \\\"schema\\\": \".concat(JSON.stringify({\n        fields: schema.fields.map(fieldToJSON)\n      }, null, 2)));\n    }\n  }, {\n    key: \"_writeDictionaries\",\n    value: function _writeDictionaries(batch) {\n      if (batch.dictionaries.size > 0) {\n        this._dictionaries.push(batch);\n      }\n\n      return this;\n    }\n  }, {\n    key: \"_writeDictionaryBatch\",\n    value: function _writeDictionaryBatch(dictionary, id) {\n      var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n\n      this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n\n      this._write(this._dictionaryBlocks.length === 0 ? \"    \" : \",\\n    \");\n\n      this._write(\"\".concat(dictionaryBatchToJSON(dictionary, id, isDelta)));\n\n      this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n\n      return this;\n    }\n  }, {\n    key: \"_writeRecordBatch\",\n    value: function _writeRecordBatch(batch) {\n      this._writeDictionaries(batch);\n\n      this._recordBatches.push(batch);\n\n      return this;\n    }\n  }, {\n    key: \"close\",\n    value: function close() {\n      if (this._dictionaries.length > 0) {\n        this._write(\",\\n  \\\"dictionaries\\\": [\\n\");\n\n        var _iterator4 = _createForOfIteratorHelper(this._dictionaries),\n            _step4;\n\n        try {\n          for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n            var batch = _step4.value;\n\n            _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"_writeDictionaries\", this).call(this, batch);\n          }\n        } catch (err) {\n          _iterator4.e(err);\n        } finally {\n          _iterator4.f();\n        }\n\n        this._write(\"\\n  ]\");\n      }\n\n      if (this._recordBatches.length > 0) {\n        for (var i = -1, n = this._recordBatches.length; ++i < n;) {\n          this._write(i === 0 ? \",\\n  \\\"batches\\\": [\\n    \" : \",\\n    \");\n\n          this._write(\"\".concat(recordBatchToJSON(this._recordBatches[i])));\n\n          this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n        }\n\n        this._write(\"\\n  ]\");\n      }\n\n      if (this._schema) {\n        this._write(\"\\n}\");\n      }\n\n      this._dictionaries = [];\n      this._recordBatches = [];\n      return _get(_getPrototypeOf(RecordBatchJSONWriter.prototype), \"close\", this).call(this);\n    }\n  }], [{\n    key: \"writeAll\",\n    value: function writeAll(input) {\n      return new RecordBatchJSONWriter().writeAll(input);\n    }\n  }]);\n\n  return RecordBatchJSONWriter;\n}(RecordBatchWriter);\n/** @ignore */\n\nfunction _writeAll(writer, input) {\n  var chunks = input;\n\n  if (input instanceof Table) {\n    chunks = input.chunks;\n    writer.reset(undefined, input.schema);\n  }\n\n  var _iterator5 = _createForOfIteratorHelper(chunks),\n      _step5;\n\n  try {\n    for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n      var batch = _step5.value;\n      writer.write(batch);\n    }\n  } catch (err) {\n    _iterator5.e(err);\n  } finally {\n    _iterator5.f();\n  }\n\n  return writer.finish();\n}\n/** @ignore */\n\n\nfunction writeAllAsync(_x, _x2) {\n  return _writeAllAsync.apply(this, arguments);\n}\n/** @ignore */\n\n\nfunction _writeAllAsync() {\n  _writeAllAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(writer, batches) {\n    var _iteratorAbruptCompletion, _didIteratorError, _iteratorError, _iterator, _step, batch;\n\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            _iteratorAbruptCompletion = false;\n            _didIteratorError = false;\n            _context.prev = 2;\n            _iterator = _asyncIterator(batches);\n\n          case 4:\n            _context.next = 6;\n            return _iterator.next();\n\n          case 6:\n            if (!(_iteratorAbruptCompletion = !(_step = _context.sent).done)) {\n              _context.next = 12;\n              break;\n            }\n\n            batch = _step.value;\n            writer.write(batch);\n\n          case 9:\n            _iteratorAbruptCompletion = false;\n            _context.next = 4;\n            break;\n\n          case 12:\n            _context.next = 18;\n            break;\n\n          case 14:\n            _context.prev = 14;\n            _context.t0 = _context[\"catch\"](2);\n            _didIteratorError = true;\n            _iteratorError = _context.t0;\n\n          case 18:\n            _context.prev = 18;\n            _context.prev = 19;\n\n            if (!(_iteratorAbruptCompletion && _iterator.return != null)) {\n              _context.next = 23;\n              break;\n            }\n\n            _context.next = 23;\n            return _iterator.return();\n\n          case 23:\n            _context.prev = 23;\n\n            if (!_didIteratorError) {\n              _context.next = 26;\n              break;\n            }\n\n            throw _iteratorError;\n\n          case 26:\n            return _context.finish(23);\n\n          case 27:\n            return _context.finish(18);\n\n          case 28:\n            return _context.abrupt(\"return\", writer.finish());\n\n          case 29:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee, null, [[2, 14, 18, 28], [19,, 23, 27]]);\n  }));\n  return _writeAllAsync.apply(this, arguments);\n}\n\nfunction fieldToJSON(_ref) {\n  var name = _ref.name,\n      type = _ref.type,\n      nullable = _ref.nullable;\n  var assembler = new JSONTypeAssembler();\n  return {\n    'name': name,\n    'nullable': nullable,\n    'type': assembler.visit(type),\n    'children': (type.children || []).map(fieldToJSON),\n    'dictionary': !DataType.isDictionary(type) ? undefined : {\n      'id': type.id,\n      'isOrdered': type.isOrdered,\n      'indexType': assembler.visit(type.indices)\n    }\n  };\n}\n/** @ignore */\n\n\nfunction dictionaryBatchToJSON(dictionary, id) {\n  var isDelta = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n  var field = new Field(\"\".concat(id), dictionary.type, dictionary.nullCount > 0);\n  var columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n  return JSON.stringify({\n    'id': id,\n    'isDelta': isDelta,\n    'data': {\n      'count': dictionary.length,\n      'columns': columns\n    }\n  }, null, 2);\n}\n/** @ignore */\n\n\nfunction recordBatchToJSON(records) {\n  return JSON.stringify({\n    'count': records.length,\n    'columns': JSONVectorAssembler.assemble(records)\n  }, null, 2);\n}","map":{"version":3,"mappings":";;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA,SAASA,KAAT,QAAsB,UAAtB;AACA,SAASC,KAAT,QAAsB,WAAtB;AAEA,SAASC,MAAT,QAAuB,WAAvB;AACA,SAASC,QAAT,QAAyB,SAAzB;AACA,SAAiBC,KAAjB,QAA8B,WAA9B;AACA,SAASC,OAAT,QAAwB,oBAAxB;AACA,OAAO,KAAKC,QAAZ,MAA0B,oBAA1B;AACA,SAASC,SAAT,EAAoBC,MAApB,QAAkC,iBAAlC;AACA,SAASC,aAAT,EAAwBC,eAAxB,QAA+C,SAA/C;AACA,SAAuBC,cAAvB,QAA6C,cAA7C;AACA,SAASC,eAAT,QAAgC,4BAAhC;AACA,SAASC,iBAAT,QAAkC,8BAAlC;AACA,SAASC,mBAAT,QAAoC,gCAApC;AACA,SAA+BC,YAA/B,QAAmD,gBAAnD;AACA,SAASC,WAAT,EAAsBC,oCAAtB,QAAkE,gBAAlE;AACA,SAAmBC,eAAnB,QAAoE,kBAApE;AACA,SAASC,SAAT,EAAoBC,eAApB,EAAqCC,mBAArC,EAA0DC,oBAA1D,EAAgFC,UAAhF,EAA4FC,QAA5F,QAA4G,gBAA5G;AAgBA,WAAaC,iBAAb;AAAA;;AAAA;;AAiBI,6BAAYC,OAAZ,EAAoD;AAAA;;AAAA;;AAChD;AAMM,sBAAY,CAAZ;AACA,qBAAW,KAAX,CAR0C,CAWpD;;AACU,kBAAQ,IAAIf,cAAJ,EAAR;AACA,oBAAyB,IAAzB;AACA,8BAAiC,EAAjC;AACA,+BAAkC,EAAlC;AACA,oCAA0B,IAAIgB,GAAJ,EAA1B;AAdNH,YAAQ,CAACE,OAAD,CAAR,KAAsBA,OAAO,GAAG;AAAEE,iBAAW,EAAE,IAAf;AAAqBC,0BAAoB,EAAE;AAA3C,KAAhC;AACA,UAAKC,YAAL,GAAqB,OAAOJ,OAAO,CAACE,WAAf,KAA+B,SAAhC,GAA6CF,OAAO,CAACE,WAArD,GAAmE,IAAvF;AACA,UAAKG,qBAAL,GAA8B,OAAOL,OAAO,CAACG,oBAAf,KAAwC,SAAzC,GAAsDH,OAAO,CAACG,oBAA9D,GAAqF,KAAlH;AAJgD;AAKnD;AApBD;AACA;;;AAHJ;AAAA;AAAA,WAqCW,oBAA0B;AAAA,UAAjBG,IAAiB,uEAAL,KAAK;AAC7B,aAAO,KAAKC,KAAL,CAAWC,QAAX,CAAoBF,IAApB,CAAP;AACH;AAvCL;AAAA;AAAA,WA0CW,wBAA8B;AAAA,UAAjBA,IAAiB,uEAAL,KAAK;AACjC,aAAO,KAAKC,KAAL,CAAWlB,YAAX,CAAwBiB,IAAxB,CAAP;AACH;AA5CL;AAAA;AAAA,WAkDW,kBAASG,KAAT,EAAsG;AAAA;;AACzG,UAAIhB,SAAS,CAAMgB,KAAN,CAAb,EAA2B;AACvB,eAAOA,KAAK,CAACC,IAAN,CAAW,UAACC,CAAD;AAAA,iBAAO,MAAI,CAACC,QAAL,CAAcD,CAAd,CAAP;AAAA,SAAX,CAAP;AACH,OAFD,MAEO,IAAIjB,eAAe,CAAiBe,KAAjB,CAAnB,EAA4C;AAC/C,eAAOI,aAAa,CAAC,IAAD,EAAOJ,KAAP,CAApB;AACH;;AACD,aAAOG,SAAQ,CAAC,IAAD,EAAaH,KAAb,CAAf;AACH;AAzDL;AAAA;AAAA,SA2DI,eAAiB;AAAK,aAAO,KAAKF,KAAL,CAAWO,MAAlB;AAA2B;AA3DrD;AAAA;AAAA,WA4DW,iBAAsB;AAAK,aAAO,KAAKP,KAAL,CAAWQ,MAAM,CAACC,aAAlB,GAAP;AAA4C;AA5DlF;AAAA;AAAA,WA6DW,qBAAYhB,OAAZ,EAA8C;AAAI,aAAO,KAAKO,KAAL,CAAWU,WAAX,CAAuBjB,OAAvB,CAAP;AAAyC;AA7DtG;AAAA;AAAA,WA8DW,sBAAaA,OAAb,EAAuD;AAAI,aAAO,KAAKO,KAAL,CAAWW,YAAX,CAAwBlB,OAAxB,CAAP;AAA0C;AA9DhH;AAAA;AAAA,WAgEW,iBAAK;AACR,aAAO,KAAKmB,KAAL,GAAaZ,KAAb,CAAmBa,KAAnB,EAAP;AACH;AAlEL;AAAA;AAAA,WAmEW,eAAMC,MAAN,EAAkB;AACrB,aAAO,KAAKF,KAAL,GAAaZ,KAAb,CAAmBe,KAAnB,CAAyBD,MAAzB,CAAP;AACH;AArEL;AAAA;AAAA,WAsEW,kBAAM;AACT,WAAKjB,YAAL,GAAoB,KAAKgB,KAAL,EAApB,GAAmC,KAAKD,KAAL,CAAW,KAAKZ,KAAhB,EAAuB,KAAKgB,OAA5B,CAAnC;AACA,aAAO,IAAP;AACH;AAzEL;AAAA;AAAA,WA0EW,iBAA4F;AAAA,UAAtFC,IAAsF,uEAA3C,KAAKjB,KAAsC;AAAA,UAA/BkB,MAA+B,uEAAJ,IAAI;;AAE/F,UAAKD,IAAI,KAAK,KAAKjB,KAAf,IAA0BiB,IAAI,YAAYvC,cAA9C,EAA+D;AAC3D,aAAKsB,KAAL,GAAaiB,IAAb;AACH,OAFD,MAEO;AACH,aAAKjB,KAAL,GAAa,IAAItB,cAAJ,EAAb;;AACA,YAAIuC,IAAI,IAAI7B,mBAAmB,CAAC6B,IAAD,CAA/B,EAAuC;AACnC,eAAKP,WAAL,CAAiB;AAAES,gBAAI,EAAE;AAAR,WAAjB,EAAoCC,MAApC,CAA2CH,IAA3C;AACH,SAFD,MAEO,IAAIA,IAAI,IAAI5B,oBAAoB,CAAC4B,IAAD,CAAhC,EAAwC;AAC3C,eAAKN,YAAL,CAAkB;AAAEU,sBAAU,EAAE;AAAd,WAAlB,EAAyCC,IAAzC,CAA8CL,IAA9C;AACH;AACJ;;AAED,UAAI,KAAKM,QAAL,IAAiB,KAAKP,OAA1B,EAAmC;AAC/B,aAAKQ,YAAL,CAAkB,KAAKR,OAAvB;AACH;;AAED,WAAKO,QAAL,GAAgB,KAAhB;AACA,WAAKE,iBAAL,GAAyB,EAAzB;AACA,WAAKC,kBAAL,GAA0B,EAA1B;AACA,WAAKC,uBAAL,GAA+B,IAAIjC,GAAJ,EAA/B;;AAEA,UAAI,CAACwB,MAAD,IAAW,CAAEA,MAAM,CAACU,SAAP,CAAiB,KAAKZ,OAAtB,CAAjB,EAAkD;AAC9C,YAAIE,MAAM,KAAK,IAAf,EAAqB;AACjB,eAAKW,SAAL,GAAiB,CAAjB;AACA,eAAKb,OAAL,GAAe,IAAf;AACH,SAHD,MAGO;AACH,eAAKO,QAAL,GAAgB,IAAhB;AACA,eAAKP,OAAL,GAAeE,MAAf;;AACA,eAAKY,YAAL,CAAkBZ,MAAlB;AACH;AACJ;;AAED,aAAO,IAAP;AACH;AA5GL;AAAA;AAAA,WA8GW,eAAMa,OAAN,EAA2E;AAE9E,UAAIb,MAAM,GAAqB,IAA/B;;AAEA,UAAI,CAAC,KAAKlB,KAAV,EAAiB;AACb,cAAM,IAAIgC,KAAJ,+BAAN;AACH,OAFD,MAEO,IAAID,OAAO,KAAK,IAAZ,IAAoBA,OAAO,KAAKE,SAApC,EAA+C;AAClD,eAAO,KAAKC,MAAL,MAAiBD,SAAxB;AACH,OAFM,MAEA,IAAIF,OAAO,YAAYhE,KAAnB,IAA4B,EAAEmD,MAAM,GAAGa,OAAO,CAACb,MAAnB,CAAhC,EAA4D;AAC/D,eAAO,KAAKgB,MAAL,MAAiBD,SAAxB;AACH,OAFM,MAEA,IAAIF,OAAO,YAAYhD,WAAnB,IAAkC,EAAEmC,MAAM,GAAGa,OAAO,CAACb,MAAnB,CAAtC,EAAkE;AACrE,eAAO,KAAKgB,MAAL,MAAiBD,SAAxB;AACH;;AAED,UAAIf,MAAM,IAAI,CAACA,MAAM,CAACU,SAAP,CAAiB,KAAKZ,OAAtB,CAAf,EAA+C;AAC3C,YAAI,KAAKO,QAAL,IAAiB,KAAK1B,YAA1B,EAAwC;AACpC,iBAAO,KAAKgB,KAAL,EAAP;AACH;;AACD,aAAKD,KAAL,CAAW,KAAKZ,KAAhB,EAAuBkB,MAAvB;AACH;;AAED,UAAIa,OAAO,YAAYhD,WAAvB,EAAoC;AAChC,YAAI,EAAEgD,OAAO,YAAY/C,oCAArB,CAAJ,EAAgE;AAC5D,eAAKmD,iBAAL,CAAuBJ,OAAvB;AACH;AACJ,OAJD,MAIO,IAAIA,OAAO,YAAYhE,KAAvB,EAA8B;AACjC,aAAKsC,QAAL,CAAc0B,OAAO,CAACK,MAAtB;AACH,OAFM,MAEA,IAAI9C,UAAU,CAACyC,OAAD,CAAd,EAAyB;AAC5B,aAAK1B,QAAL,CAAc0B,OAAd;AACH;AACJ;AA5IL;AAAA;AAAA,WA8Ic,uBAAuCM,OAAvC,EAAyE;AAAA,UAAbC,SAAa,uEAAD,CAAC;AAE/E,UAAMC,CAAC,GAAGD,SAAS,GAAG,CAAtB;AACA,UAAME,MAAM,GAAGpE,OAAO,CAACqE,MAAR,CAAeJ,OAAf,CAAf;AACA,UAAMK,cAAc,GAAGF,MAAM,CAACG,UAA9B;AACA,UAAMC,UAAU,GAAG,CAAC,KAAK9C,qBAAN,GAA8B,CAA9B,GAAkC,CAArD;AACA,UAAM+C,WAAW,GAAIH,cAAc,GAAGE,UAAjB,GAA8BL,CAA/B,GAAoC,CAACA,CAAzD;AACA,UAAMO,aAAa,GAAGD,WAAW,GAAGH,cAAd,GAA+BE,UAArD;;AAEA,UAAIP,OAAO,CAACU,UAAR,KAAuBvE,aAAa,CAACO,WAAzC,EAAsD;AAClD,aAAK2C,kBAAL,CAAwBsB,IAAxB,CAA6B,IAAI1E,SAAJ,CAAcuE,WAAd,EAA2BR,OAAO,CAACY,UAAnC,EAA+C,KAAKpB,SAApD,CAA7B;AACH,OAFD,MAEO,IAAIQ,OAAO,CAACU,UAAR,KAAuBvE,aAAa,CAAC0E,eAAzC,EAA0D;AAC7D,aAAKzB,iBAAL,CAAuBuB,IAAvB,CAA4B,IAAI1E,SAAJ,CAAcuE,WAAd,EAA2BR,OAAO,CAACY,UAAnC,EAA+C,KAAKpB,SAApD,CAA5B;AACH,OAb8E,CAe/E;;;AACA,UAAI,CAAC,KAAK/B,qBAAV,EAAiC;AAC7B,aAAKqD,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAC,CAAf,CAAZ;AACH,OAlB8E,CAmB/E;;;AACA,WAAKF,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAcR,WAAW,GAAGD,UAA5B,CAAZ,EApB+E,CAqB/E;;;AACA,UAAIF,cAAc,GAAG,CAArB,EAAwB;AAAE,aAAKS,MAAL,CAAYX,MAAZ;AAAsB,OAtB+B,CAuB/E;;;AACA,aAAO,KAAKc,aAAL,CAAmBR,aAAnB,CAAP;AACH;AAvKL;AAAA;AAAA,WAyKc,gBAAOS,KAAP,EAAkC;AACxC,UAAI,KAAKhC,QAAT,EAAmB;AACf,YAAMiB,MAAM,GAAG1D,YAAY,CAACyE,KAAD,CAA3B;;AACA,YAAIf,MAAM,IAAIA,MAAM,CAACG,UAAP,GAAoB,CAAlC,EAAqC;AACjC,eAAK3C,KAAL,CAAWwD,KAAX,CAAiBhB,MAAjB;;AACA,eAAKX,SAAL,IAAkBW,MAAM,CAACG,UAAzB;AACH;AACJ;;AACD,aAAO,IAAP;AACH;AAlLL;AAAA;AAAA,WAoLc,sBAAazB,MAAb,EAA8B;AACpC,aAAO,KAAKuC,aAAL,CAAmBrF,OAAO,CAACsF,IAAR,CAAaxC,MAAb,CAAnB,CAAP;AACH,KAtLL,CAwLI;;AAxLJ;AAAA;AAAA,WAyLc,sBAAaA,MAAb,EAA8B;AACpC;AACA,aAAO,KAAKpB,qBAAL,GACD,KAAKqD,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAd,CAAZ,CADC,GAED,KAAKF,MAAL,CAAYC,UAAU,CAACC,EAAX,CAAc,CAAC,CAAf,EAAkB,CAAlB,CAAZ,CAFN;AAGH;AA9LL;AAAA;AAAA,WAgMc,uBAAW;AACjB,aAAO,KAAKF,MAAL,CAAYnF,KAAZ,CAAP;AACH;AAlML;AAAA;AAAA,WAoMc,uBAAc2F,MAAd,EAA4B;AAClC,aAAOA,MAAM,GAAG,CAAT,GAAa,KAAKR,MAAL,CAAY,IAAIS,UAAJ,CAAeD,MAAf,CAAZ,CAAb,GAAmD,IAA1D;AACH;AAtML;AAAA;AAAA,WAwMc,2BAAkBE,KAAlB,EAAuC;AAC7C,kCAAsDlF,eAAe,CAACmF,QAAhB,CAAyBD,KAAzB,CAAtD;AAAA,UAAQlB,UAAR,yBAAQA,UAAR;AAAA,UAAoBoB,KAApB,yBAAoBA,KAApB;AAAA,UAA2BC,aAA3B,yBAA2BA,aAA3B;AAAA,UAA0CC,OAA1C,yBAA0CA,OAA1C;;AACA,UAAMC,WAAW,GAAG,IAAI7F,QAAQ,CAACU,WAAb,CAAyB8E,KAAK,CAACM,MAA/B,EAAuCJ,KAAvC,EAA8CC,aAA9C,CAApB;AACA,UAAM3B,OAAO,GAAGjE,OAAO,CAACsF,IAAR,CAAaQ,WAAb,EAA0BvB,UAA1B,CAAhB;AACA,aAAO,KACFyB,kBADE,CACiBP,KADjB,EAEFJ,aAFE,CAEYpB,OAFZ,EAGFgC,iBAHE,CAGgBJ,OAHhB,CAAP;AAIH;AAhNL;AAAA;AAAA,WAkNc,+BAAsBK,UAAtB,EAA0CC,EAA1C,EAAqE;AAAA,UAAfC,OAAe,uEAAL,KAAK;;AAC3E,WAAK7C,uBAAL,CAA6B8C,GAA7B,CAAiCF,EAAjC,EAAqCD,UAAU,CAACH,MAAX,IAAqB,KAAKxC,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAA7D,CAArC;;AACA,mCAAsD5F,eAAe,CAACmF,QAAhB,CAAyBQ,UAAzB,CAAtD;AAAA,UAAQ3B,UAAR,0BAAQA,UAAR;AAAA,UAAoBoB,KAApB,0BAAoBA,KAApB;AAAA,UAA2BC,aAA3B,0BAA2BA,aAA3B;AAAA,UAA0CC,OAA1C,0BAA0CA,OAA1C;;AACA,UAAMC,WAAW,GAAG,IAAI7F,QAAQ,CAACU,WAAb,CAAyBuF,UAAU,CAACH,MAApC,EAA4CJ,KAA5C,EAAmDC,aAAnD,CAApB;AACA,UAAMW,eAAe,GAAG,IAAItG,QAAQ,CAAC6E,eAAb,CAA6BgB,WAA7B,EAA0CK,EAA1C,EAA8CC,OAA9C,CAAxB;AACA,UAAMnC,OAAO,GAAGjE,OAAO,CAACsF,IAAR,CAAaiB,eAAb,EAA8BhC,UAA9B,CAAhB;AACA,aAAO,KACFc,aADE,CACYpB,OADZ,EAEFgC,iBAFE,CAEgBJ,OAFhB,CAAP;AAGH;AA3NL;AAAA;AAAA,WA6Nc,2BAAkBA,OAAlB,EAA4C;AAClD,UAAIzB,MAAJ;AACA,UAAIoC,IAAJ,EAAkBC,OAAlB;;AACA,WAAK,IAAIC,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAGd,OAAO,CAACE,MAA7B,EAAqC,EAAEW,CAAF,GAAMC,CAA3C,GAA+C;AAC3C,YAAI,CAACvC,MAAM,GAAGyB,OAAO,CAACa,CAAD,CAAjB,KAAyB,CAACF,IAAI,GAAGpC,MAAM,CAACG,UAAf,IAA6B,CAA1D,EAA6D;AACzD,eAAKQ,MAAL,CAAYX,MAAZ;;AACA,cAAI,CAACqC,OAAO,GAAG,CAAED,IAAI,GAAG,CAAR,GAAa,CAAC,CAAf,IAAoBA,IAA/B,IAAuC,CAA3C,EAA8C;AAC1C,iBAAKtB,aAAL,CAAmBuB,OAAnB;AACH;AACJ;AACJ;;AACD,aAAO,IAAP;AACH;AAzOL;AAAA;AAAA,WA2Oc,4BAAmBhB,KAAnB,EAAwC;AAAA,kDACjBA,KAAK,CAACmB,YADW;AAAA;;AAAA;AAC9C,+DAAiD;AAAA;AAAA,cAAvCT,EAAuC;AAAA,cAAnCD,UAAmC;;AAC7C,cAAIW,MAAM,GAAG,KAAKtD,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAArD;;AACA,cAAIU,MAAM,KAAK,CAAX,IAAgB,CAACX,UAAU,GAAGA,UAAU,CAACY,KAAX,CAAiBD,MAAjB,CAAd,EAAwCd,MAAxC,GAAiD,CAArE,EAAwE;AACpE,gBAAM/B,MAAM,GAAG,YAAYkC,UAAZ,GAA0BA,UAAkB,CAAClC,MAA7C,GAAsD,CAACkC,UAAD,CAArE;;AADoE,wDAEhDlC,MAFgD;AAAA;;AAAA;AAEpE,qEAA4B;AAAA,oBAAjBmB,KAAiB;;AACxB,qBAAK4B,qBAAL,CAA2B5B,KAA3B,EAAkCgB,EAAlC,EAAsCU,MAAM,GAAG,CAA/C;;AACAA,sBAAM,IAAI1B,KAAK,CAACY,MAAhB;AACH;AALmE;AAAA;AAAA;AAAA;AAAA;AAMvE;AACJ;AAV6C;AAAA;AAAA;AAAA;AAAA;;AAW9C,aAAO,IAAP;AACH;AAvPL;AAAA;AAAA,WAIW,qBAAmB1E,OAAnB,EAAsF;AACzF,YAAM,IAAIuC,KAAJ,qDAAN;AACH;AACD;;AAPJ;AAAA;AAAA,WAQW,qBACH;AACAoD,oBAFG,EAGH;AACAC,oBAJG,EAIsD;AAEzD,YAAM,IAAIrD,KAAJ,oDAAN;AACH;AAfL;;AAAA;AAAA,EAAoF/C,eAApF,EA4DYuB,MAAM,CAACC,aA5DnB;AA0PA;;AACA,WAAa6E,uBAAb;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAKI;AACO,sBAA6DpF,KAA7D,EAAyET,OAAzE,EAAiH;AACpH,UAAM8F,MAAM,GAAG,IAAID,uBAAJ,CAA+B7F,OAA/B,CAAf;;AACA,UAAIP,SAAS,CAAMgB,KAAN,CAAb,EAA2B;AACvB,eAAOA,KAAK,CAACC,IAAN,CAAW,UAACC,CAAD;AAAA,iBAAOmF,MAAM,CAAClF,QAAP,CAAgBD,CAAhB,CAAP;AAAA,SAAX,CAAP;AACH,OAFD,MAEO,IAAIjB,eAAe,CAAiBe,KAAjB,CAAnB,EAA4C;AAC/C,eAAOI,aAAa,CAACiF,MAAD,EAASrF,KAAT,CAApB;AACH;;AACD,aAAOG,SAAQ,CAACkF,MAAD,EAASrF,KAAT,CAAf;AACH;AAdL;;AAAA;AAAA,EAA0FV,iBAA1F;AAiBA;;AACA,WAAagG,qBAAb;AAAA;;AAAA;;AAgBI;AAAA;;AAAA;;AACI;AACA,WAAK3F,YAAL,GAAoB,IAApB;AAFJ;AAGC;AAdD;;;AALJ;AAAA;AAAA,WAqBI;AACU,0BAAaqB,MAAb,EAA8B;AACpC,aAAO,KAAKuE,WAAL,GAAmBnC,aAAnB,CAAiC,CAAjC,CAAP;AACH;AAxBL;AAAA;AAAA,WA0Bc,sBAAapC,MAAb,EAA8B;AACpC,UAAMsB,MAAM,GAAGjE,MAAM,CAACkE,MAAP,CAAc,IAAIlE,MAAJ,CACzB2C,MADyB,EACjBzC,eAAe,CAACiH,EADC,EAEzB,KAAKhE,kBAFoB,EAEA,KAAKD,iBAFL,CAAd,CAAf;AAIA,aAAO,wFACWP,MADX,EACmB;AADnB,OAEFiC,MAFE,CAEKX,MAFL,EAEa;AAFb,OAGFW,MAHE,CAGKC,UAAU,CAACC,EAAX,CAAcb,MAAM,CAACG,UAArB,CAHL,EAGuC;AAHvC,OAIF8C,WAJE,EAAP,CALoC,CAShB;AACvB;AApCL;AAAA;AAAA,WAMW,kBAA6DvF,KAA7D,EAAuE;AAC1E,UAAMqF,MAAM,GAAG,IAAIC,qBAAJ,EAAf;;AACA,UAAItG,SAAS,CAAMgB,KAAN,CAAb,EAA2B;AACvB,eAAOA,KAAK,CAACC,IAAN,CAAW,UAACC,CAAD;AAAA,iBAAOmF,MAAM,CAAClF,QAAP,CAAgBD,CAAhB,CAAP;AAAA,SAAX,CAAP;AACH,OAFD,MAEO,IAAIjB,eAAe,CAAiBe,KAAjB,CAAnB,EAA4C;AAC/C,eAAOI,aAAa,CAACiF,MAAD,EAASrF,KAAT,CAApB;AACH;;AACD,aAAOG,SAAQ,CAACkF,MAAD,EAASrF,KAAT,CAAf;AACH;AAdL;;AAAA;AAAA,EAAwFV,iBAAxF;AAuCA;;AACA,WAAamG,qBAAb;AAAA;;AAAA;;AAeI;AAAA;;AAAA;;AACI;AACA,WAAK9F,YAAL,GAAoB,IAApB;AACA,WAAK+F,cAAL,GAAsB,EAAtB;AACA,WAAKC,aAAL,GAAqB,EAArB;AAJJ;AAKC;AAbD;;;AAPJ;AAAA;AAAA,WAsBc,yBAAa;AAAK,aAAO,IAAP;AAAc,KAtB9C,CAuBI;;AAvBJ;AAAA;AAAA,WAwBc,sBAAa3E,MAAb,EAA8B;AAAI,aAAO,IAAP;AAAc;AAxB9D;AAAA;AAAA,WAyBc,sBAAaA,MAAb,EAA8B;AACpC,aAAO,KAAKiC,MAAL,4BACH2C,IAAI,CAACC,SAAL,CAAe;AAAEC,cAAM,EAAE9E,MAAM,CAAC8E,MAAP,CAAcC,GAAd,CAAkBC,WAAlB;AAAV,OAAf,EAA2D,IAA3D,EAAiE,CAAjE,CADG,EAAP;AAGH;AA7BL;AAAA;AAAA,WA8Bc,4BAAmBrC,KAAnB,EAAwC;AAC9C,UAAIA,KAAK,CAACmB,YAAN,CAAmBJ,IAAnB,GAA0B,CAA9B,EAAiC;AAC7B,aAAKiB,aAAL,CAAmB7C,IAAnB,CAAwBa,KAAxB;AACH;;AACD,aAAO,IAAP;AACH;AAnCL;AAAA;AAAA,WAoCc,+BAAsBS,UAAtB,EAA0CC,EAA1C,EAAqE;AAAA,UAAfC,OAAe,uEAAL,KAAK;;AAC3E,WAAK7C,uBAAL,CAA6B8C,GAA7B,CAAiCF,EAAjC,EAAqCD,UAAU,CAACH,MAAX,IAAqB,KAAKxC,uBAAL,CAA6B+C,GAA7B,CAAiCH,EAAjC,KAAwC,CAA7D,CAArC;;AACA,WAAKpB,MAAL,CAAY,KAAK1B,iBAAL,CAAuB0C,MAAvB,KAAkC,CAAlC,qBAAZ;;AACA,WAAKhB,MAAL,WAAegD,qBAAqB,CAAC7B,UAAD,EAAaC,EAAb,EAAiBC,OAAjB,CAApC;;AACA,WAAK/C,iBAAL,CAAuBuB,IAAvB,CAA4B,IAAI1E,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoB,CAApB,CAA5B;;AACA,aAAO,IAAP;AACH;AA1CL;AAAA;AAAA,WA2Cc,2BAAkBuF,KAAlB,EAAuC;AAC7C,WAAKO,kBAAL,CAAwBP,KAAxB;;AACA,WAAK+B,cAAL,CAAoB5C,IAApB,CAAyBa,KAAzB;;AACA,aAAO,IAAP;AACH;AA/CL;AAAA;AAAA,WAgDW,iBAAK;AAER,UAAI,KAAKgC,aAAL,CAAmB1B,MAAnB,GAA4B,CAAhC,EAAmC;AAC/B,aAAKhB,MAAL;;AAD+B,oDAEX,KAAK0C,aAFM;AAAA;;AAAA;AAE/B,iEAAwC;AAAA,gBAA7BhC,KAA6B;;AACpC,0GAAyBA,KAAzB;AACH;AAJ8B;AAAA;AAAA;AAAA;AAAA;;AAK/B,aAAKV,MAAL;AACH;;AAED,UAAI,KAAKyC,cAAL,CAAoBzB,MAApB,GAA6B,CAAjC,EAAoC;AAChC,aAAK,IAAIW,CAAC,GAAG,CAAC,CAAT,EAAYC,CAAC,GAAG,KAAKa,cAAL,CAAoBzB,MAAzC,EAAiD,EAAEW,CAAF,GAAMC,CAAvD,GAA2D;AACvD,eAAK5B,MAAL,CAAY2B,CAAC,KAAK,CAAN,0CAAZ;;AACA,eAAK3B,MAAL,WAAeiD,iBAAiB,CAAC,KAAKR,cAAL,CAAoBd,CAApB,CAAD,CAAhC;;AACA,eAAKpD,kBAAL,CAAwBsB,IAAxB,CAA6B,IAAI1E,SAAJ,CAAc,CAAd,EAAiB,CAAjB,EAAoB,CAApB,CAA7B;AACH;;AACD,aAAK6E,MAAL;AACH;;AAED,UAAI,KAAKnC,OAAT,EAAkB;AACd,aAAKmC,MAAL;AACH;;AAED,WAAK0C,aAAL,GAAqB,EAArB;AACA,WAAKD,cAAL,GAAsB,EAAtB;AAEA;AACH;AA3EL;AAAA;AAAA,WAQW,kBAA6F1F,KAA7F,EAAuG;AAC1G,aAAO,IAAIyF,qBAAJ,GAA+BtF,QAA/B,CAAwCH,KAAxC,CAAP;AACH;AAVL;;AAAA;AAAA,EAAwFV,iBAAxF;AA8EA;;AACA,SAASa,SAAT,CAA+DkF,MAA/D,EAA6FrF,KAA7F,EAAuI;AACnI,MAAIkC,MAAM,GAAGlC,KAAb;;AACA,MAAIA,KAAK,YAAYnC,KAArB,EAA4B;AACxBqE,UAAM,GAAGlC,KAAK,CAACkC,MAAf;AACAmD,UAAM,CAAC3E,KAAP,CAAaqB,SAAb,EAAwB/B,KAAK,CAACgB,MAA9B;AACH;;AALkI,8CAM/GkB,MAN+G;AAAA;;AAAA;AAMnI,2DAA4B;AAAA,UAAjByB,KAAiB;AACxB0B,YAAM,CAAC/B,KAAP,CAAaK,KAAb;AACH;AARkI;AAAA;AAAA;AAAA;AAAA;;AASnI,SAAO0B,MAAM,CAACrD,MAAP,EAAP;AACH;AAED;;;SACe5B,a;;;AAOf;;;;4EAPA,iBAA0EiF,MAA1E,EAAwGc,OAAxG;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uCAC8BA,OAD9B;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AACqBxC,iBADrB;AAEQ0B,kBAAM,CAAC/B,KAAP,CAAaK,KAAb;;AAFR;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;;AAAA;AAAA,6CAIW0B,MAAM,CAACrD,MAAP,EAJX;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAQA,SAASgE,WAAT,OAAoD;AAAA,MAA7BI,IAA6B,QAA7BA,IAA6B;AAAA,MAAvBnF,IAAuB,QAAvBA,IAAuB;AAAA,MAAjBoF,QAAiB,QAAjBA,QAAiB;AAChD,MAAMC,SAAS,GAAG,IAAI5H,iBAAJ,EAAlB;AACA,SAAO;AACH,YAAQ0H,IADL;AACW,gBAAYC,QADvB;AAEH,YAAQC,SAAS,CAACC,KAAV,CAAgBtF,IAAhB,CAFL;AAGH,gBAAY,CAACA,IAAI,CAACuF,QAAL,IAAiB,EAAlB,EAAsBT,GAAtB,CAA0BC,WAA1B,CAHT;AAIH,kBAAc,CAAChI,QAAQ,CAACyI,YAAT,CAAsBxF,IAAtB,CAAD,GAA+Bc,SAA/B,GAA2C;AACrD,YAAMd,IAAI,CAACoD,EAD0C;AAErD,mBAAapD,IAAI,CAACyF,SAFmC;AAGrD,mBAAaJ,SAAS,CAACC,KAAV,CAAgBtF,IAAI,CAAC0F,OAArB;AAHwC;AAJtD,GAAP;AAUH;AAED;;;AACA,SAASV,qBAAT,CAA+B7B,UAA/B,EAAmDC,EAAnD,EAA8E;AAAA,MAAfC,OAAe,uEAAL,KAAK;AAC1E,MAAMsC,KAAK,GAAG,IAAI3I,KAAJ,WAAaoG,EAAb,GAAmBD,UAAU,CAACnD,IAA9B,EAAoCmD,UAAU,CAACyC,SAAX,GAAuB,CAA3D,CAAd;AACA,MAAMC,OAAO,GAAGnI,mBAAmB,CAACiF,QAApB,CAA6B,IAAI7F,MAAJ,CAAW6I,KAAX,EAAkB,CAACxC,UAAD,CAAlB,CAA7B,CAAhB;AACA,SAAOwB,IAAI,CAACC,SAAL,CAAe;AAClB,UAAMxB,EADY;AAElB,eAAWC,OAFO;AAGlB,YAAQ;AACJ,eAASF,UAAU,CAACH,MADhB;AAEJ,iBAAW6C;AAFP;AAHU,GAAf,EAOJ,IAPI,EAOE,CAPF,CAAP;AAQH;AAED;;;AACA,SAASZ,iBAAT,CAA2Ba,OAA3B,EAA+C;AAC3C,SAAOnB,IAAI,CAACC,SAAL,CAAe;AAClB,aAASkB,OAAO,CAAC9C,MADC;AAElB,eAAWtF,mBAAmB,CAACiF,QAApB,CAA6BmD,OAA7B;AAFO,GAAf,EAGJ,IAHI,EAGE,CAHF,CAAP;AAIH","names":["Table","MAGIC","Column","DataType","Field","Message","metadata","FileBlock","Footer","MessageHeader","MetadataVersion","AsyncByteQueue","VectorAssembler","JSONTypeAssembler","JSONVectorAssembler","toUint8Array","RecordBatch","_InternalEmptyPlaceholderRecordBatch","ReadableInterop","isPromise","isAsyncIterable","isWritableDOMStream","isWritableNodeStream","isIterable","isObject","RecordBatchWriter","options","Map","autoDestroy","writeLegacyIpcFormat","_autoDestroy","_writeLegacyIpcFormat","sync","_sink","toString","input","then","x","writeAll","writeAllAsync","closed","Symbol","asyncIterator","toDOMStream","toNodeStream","reset","close","reason","abort","_schema","sink","schema","type","pipeTo","objectMode","pipe","_started","_writeFooter","_dictionaryBlocks","_recordBatchBlocks","_dictionaryDeltaOffsets","compareTo","_position","_writeSchema","payload","Error","undefined","finish","_writeRecordBatch","chunks","message","alignment","a","buffer","encode","flatbufferSize","byteLength","prefixSize","alignedSize","nPaddingBytes","headerType","push","bodyLength","DictionaryBatch","_write","Int32Array","of","_writePadding","chunk","write","_writeMessage","from","nBytes","Uint8Array","batch","assemble","nodes","bufferRegions","buffers","recordBatch","length","_writeDictionaries","_writeBodyBuffers","dictionary","id","isDelta","set","get","dictionaryBatch","size","padding","i","n","dictionaries","offset","slice","_writeDictionaryBatch","writableStrategy","readableStrategy","RecordBatchStreamWriter","writer","RecordBatchFileWriter","_writeMagic","V4","RecordBatchJSONWriter","_recordBatches","_dictionaries","JSON","stringify","fields","map","fieldToJSON","dictionaryBatchToJSON","recordBatchToJSON","batches","name","nullable","assembler","visit","children","isDictionary","isOrdered","indices","field","nullCount","columns","records"],"sources":["ipc/writer.ts"],"sourcesContent":["// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\n\nimport { Table } from '../table';\nimport { MAGIC } from './message';\nimport { Vector } from '../vector';\nimport { Column } from '../column';\nimport { DataType } from '../type';\nimport { Schema, Field } from '../schema';\nimport { Message } from './metadata/message';\nimport * as metadata from './metadata/message';\nimport { FileBlock, Footer } from './metadata/file';\nimport { MessageHeader, MetadataVersion } from '../enum';\nimport { WritableSink, AsyncByteQueue } from '../io/stream';\nimport { VectorAssembler } from '../visitor/vectorassembler';\nimport { JSONTypeAssembler } from '../visitor/jsontypeassembler';\nimport { JSONVectorAssembler } from '../visitor/jsonvectorassembler';\nimport { ArrayBufferViewInput, toUint8Array } from '../util/buffer';\nimport { RecordBatch, _InternalEmptyPlaceholderRecordBatch } from '../recordbatch';\nimport { Writable, ReadableInterop, ReadableDOMStreamOptions } from '../io/interfaces';\nimport { isPromise, isAsyncIterable, isWritableDOMStream, isWritableNodeStream, isIterable, isObject } from '../util/compat';\n\nexport interface RecordBatchStreamWriterOptions {\n    /**\n     *\n     */\n    autoDestroy?: boolean;\n    /**\n     * A flag indicating whether the RecordBatchWriter should construct pre-0.15.0\n     * encapsulated IPC Messages, which reserves  4 bytes for the Message metadata\n     * length instead of 8.\n     * @see https://issues.apache.org/jira/browse/ARROW-6313\n     */\n    writeLegacyIpcFormat?: boolean;\n}\n\nexport class RecordBatchWriter<T extends { [key: string]: DataType } = any> extends ReadableInterop<Uint8Array> implements Writable<RecordBatch<T>> {\n\n    /** @nocollapse */\n    // @ts-ignore\n    public static throughNode(options?: import('stream').DuplexOptions & { autoDestroy: boolean }): import('stream').Duplex {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    public static throughDOM<T extends { [key: string]: DataType }>(\n        // @ts-ignore\n        writableStrategy?: QueuingStrategy<RecordBatch<T>> & { autoDestroy: boolean },\n        // @ts-ignore\n        readableStrategy?: { highWaterMark?: number, size?: any }\n    ): { writable: WritableStream<Table<T> | RecordBatch<T>>, readable: ReadableStream<Uint8Array> } {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n\n    constructor(options?: RecordBatchStreamWriterOptions) {\n        super();\n        isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n\n    protected _position = 0;\n    protected _started = false;\n    protected _autoDestroy: boolean;\n    protected _writeLegacyIpcFormat: boolean;\n    // @ts-ignore\n    protected _sink = new AsyncByteQueue();\n    protected _schema: Schema | null = null;\n    protected _dictionaryBlocks: FileBlock[] = [];\n    protected _recordBatchBlocks: FileBlock[] = [];\n    protected _dictionaryDeltaOffsets = new Map<number, number>();\n\n    public toString(sync: true): string;\n    public toString(sync?: false): Promise<string>;\n    public toString(sync: any = false) {\n        return this._sink.toString(sync) as Promise<string> | string;\n    }\n    public toUint8Array(sync: true): Uint8Array;\n    public toUint8Array(sync?: false): Promise<Uint8Array>;\n    public toUint8Array(sync: any = false) {\n        return this._sink.toUint8Array(sync) as Promise<Uint8Array> | Uint8Array;\n    }\n\n    public writeAll(input: Table<T> | Iterable<RecordBatch<T>>): this;\n    public writeAll(input: AsyncIterable<RecordBatch<T>>): Promise<this>;\n    public writeAll(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<this>;\n    public writeAll(input: PromiseLike<any> | Table<T> | Iterable<RecordBatch<T>> | AsyncIterable<RecordBatch<T>>) {\n        if (isPromise<any>(input)) {\n            return input.then((x) => this.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, <any> input);\n    }\n\n    public get closed() { return this._sink.closed; }\n    public [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    public toDOMStream(options?: ReadableDOMStreamOptions) { return this._sink.toDOMStream(options); }\n    public toNodeStream(options?: import('stream').ReadableOptions) { return this._sink.toNodeStream(options); }\n\n    public close() {\n        return this.reset()._sink.close();\n    }\n    public abort(reason?: any) {\n        return this.reset()._sink.abort(reason);\n    }\n    public finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    public reset(sink: WritableSink<ArrayBufferViewInput> = this._sink, schema: Schema<T> | null = null) {\n\n        if ((sink === this._sink) || (sink instanceof AsyncByteQueue)) {\n            this._sink = sink as AsyncByteQueue;\n        } else {\n            this._sink = new AsyncByteQueue();\n            if (sink && isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            } else if (sink && isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n\n        if (!schema || !(schema.compareTo(this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            } else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n\n        return this;\n    }\n\n    public write(payload?: Table<T> | RecordBatch<T> | Iterable<RecordBatch<T>> | null) {\n\n        let schema: Schema<T> | null = null;\n\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        } else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        } else if (payload instanceof Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        } else if (payload instanceof RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n\n        if (schema && !schema.compareTo(this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n\n        if (payload instanceof RecordBatch) {\n            if (!(payload instanceof _InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        } else if (payload instanceof Table) {\n            this.writeAll(payload.chunks);\n        } else if (isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n\n    protected _writeMessage<T extends MessageHeader>(message: Message<T>, alignment = 8) {\n\n        const a = alignment - 1;\n        const buffer = Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n\n        if (message.headerType === MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        } else if (message.headerType === MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) { this._write(buffer); }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n\n    protected _write(chunk: ArrayBufferViewInput) {\n        if (this._started) {\n            const buffer = toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMessage(Message.from(schema));\n    }\n\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n\n    protected _writeMagic() {\n        return this._write(MAGIC);\n    }\n\n    protected _writePadding(nBytes: number) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n\n    protected _writeBodyBuffers(buffers: ArrayBufferView[]) {\n        let buffer: ArrayBufferView;\n        let size: number, padding: number;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? (dictionary as any).chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\n\n/** @ignore */\nexport class RecordBatchStreamWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): RecordBatchStreamWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>, options?: RecordBatchStreamWriterOptions): Promise<RecordBatchStreamWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any, options?: RecordBatchStreamWriterOptions) {\n        const writer = new RecordBatchStreamWriter<T>(options);\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\n\n/** @ignore */\nexport class RecordBatchFileWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchFileWriter<T>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchFileWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(input: any) {\n        const writer = new RecordBatchFileWriter<T>();\n        if (isPromise<any>(input)) {\n            return input.then((x) => writer.writeAll(x));\n        } else if (isAsyncIterable<RecordBatch<T>>(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n\n    // @ts-ignore\n    protected _writeSchema(schema: Schema<T>) {\n        return this._writeMagic()._writePadding(2);\n    }\n\n    protected _writeFooter(schema: Schema<T>) {\n        const buffer = Footer.encode(new Footer(\n            schema, MetadataVersion.V4,\n            this._recordBatchBlocks, this._dictionaryBlocks\n        ));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\n\n/** @ignore */\nexport class RecordBatchJSONWriter<T extends { [key: string]: DataType } = any> extends RecordBatchWriter<T> {\n\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: Table<T> | Iterable<RecordBatch<T>>): RecordBatchJSONWriter<T>;\n    // @ts-ignore\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: AsyncIterable<RecordBatch<T>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<AsyncIterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: PromiseLike<Table<T> | Iterable<RecordBatch<T>>>): Promise<RecordBatchJSONWriter<T>>;\n    /** @nocollapse */\n    public static writeAll<T extends { [key: string]: DataType } = any>(this: typeof RecordBatchWriter, input: any) {\n        return new RecordBatchJSONWriter<T>().writeAll(input as any);\n    }\n\n    private _recordBatches: RecordBatch[];\n    private _dictionaries: RecordBatch[];\n\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n\n    protected _writeMessage() { return this; }\n    // @ts-ignore\n    protected _writeFooter(schema: Schema<T>) { return this; }\n    protected _writeSchema(schema: Schema<T>) {\n        return this._write(`{\\n  \"schema\": ${\n            JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)\n        }`);\n    }\n    protected _writeDictionaries(batch: RecordBatch<T>) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    protected _writeDictionaryBatch(dictionary: Vector, id: number, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new FileBlock(0, 0, 0));\n        return this;\n    }\n    protected _writeRecordBatch(batch: RecordBatch<T>) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    public close() {\n\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n\n        this._dictionaries = [];\n        this._recordBatches = [];\n\n        return super.close();\n    }\n}\n\n/** @ignore */\nfunction writeAll<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, input: Table<T> | Iterable<RecordBatch<T>>) {\n    let chunks = input as Iterable<RecordBatch<T>>;\n    if (input instanceof Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nasync function writeAllAsync<T extends { [key: string]: DataType } = any>(writer: RecordBatchWriter<T>, batches: AsyncIterable<RecordBatch<T>>) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }: Field): object {\n    const assembler = new JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary: Vector, id: number, isDelta = false) {\n    const field = new Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = JSONVectorAssembler.assemble(new Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n\n/** @ignore */\nfunction recordBatchToJSON(records: RecordBatch) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n"]},"metadata":{},"sourceType":"module"}